{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba100d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoyu/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import os\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from random import shuffle\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import collections\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from util.args_parser import parser\n",
    "from model.QACGBERT import BertConfig\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from util.optimization import BERTAdam\n",
    "from util.processor import (Sentihood_NLI_M_Processor,\n",
    "                            Semeval_NLI_M_Processor,\n",
    "                            Persent_Processor)\n",
    "\n",
    "from util.tokenization import *\n",
    "\n",
    "from util.evaluation import *\n",
    "\n",
    "from util.train_helper import *\n",
    "\n",
    "from model.QACGLONG import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8023e22",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c94220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/27/2022 17:07:52 - INFO - util.train_helper -   *** Model Config ***\n",
      "07/27/2022 17:07:52 - INFO - util.train_helper -   {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"full_pooler\": false,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"sep_token_id\": 2,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "07/27/2022 17:07:52 - INFO - util.train_helper -   model = QACGLONG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_weight = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/27/2022 17:07:56 - INFO - util.train_helper -   retraining with saved model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longformer/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Obtain data\n",
    "processor = Persent_Processor()\n",
    "label_list = processor.get_labels()\n",
    "train_examples = processor.get_train_examples('../datasets/persent/')[:3]\n",
    "\n",
    "# Initialize model and tokenizer\n",
    "model1, optimizer, tokenizer = getModelOptimizerTokenizer(model_type='QACGLONG',\n",
    "                                   vocab_file='BERT-Google/vocab.txt',\n",
    "                                   config_file='Longformer/config.json',\n",
    "                                   init_checkpoint='Longformer/pytorch_model.bin',\n",
    "                                   label_list=label_list,\n",
    "                                   do_lower_case=True,\n",
    "                                   num_train_steps=1,\n",
    "                                   learning_rate=1e-4,\n",
    "                                   base_learning_rate=5e-5,\n",
    "                                   warmup_proportion=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848bdf60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QACGBertForSequenceClassification1(\n",
       "  (bert): ContextBertModel1(\n",
       "    (embeddings): BERTEmbeddings1(\n",
       "      (word_embeddings): Embedding(50265, 768)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BERTLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ContextBERTEncoder1(\n",
       "      (context_layer): ModuleList(\n",
       "        (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (1): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (2): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (3): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (4): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (5): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (6): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (7): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (8): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (9): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (10): Linear(in_features=1536, out_features=768, bias=True)\n",
       "        (11): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      )\n",
       "      (layer): ModuleList(\n",
       "        (0): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ContextBERTLayer1(\n",
       "          (attention): ContextBERTAttention1(\n",
       "            (self): ContextBERTSelfAttention1(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (context_for_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (lambda_q_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_q_query_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_context_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_k_key_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "              (lambda_act): Sigmoid()\n",
       "              (quasi_act): Sigmoid()\n",
       "            )\n",
       "            (output): BERTSelfOutput1(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BERTLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BERTIntermediate1(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BERTOutput1(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BERTLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): ContextBERTPooler1(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "    (context_embeddings): Embedding(2375, 768)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac31e8",
   "metadata": {},
   "source": [
    "# Initialize Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb115675",
   "metadata": {},
   "outputs": [],
   "source": [
    "longModel = ContextBertModel1(model1.config)\n",
    "longEmbedding = BERTEmbeddings1(model1.config)\n",
    "longEncoder = ContextBERTEncoder1(model1.config)\n",
    "\n",
    "longSelfAttn = ContextBERTSelfAttention1(model1.config, 0)\n",
    "longSelfOut = BERTSelfOutput1(model1.config)\n",
    "\n",
    "longAttention = ContextBERTAttention1(model1.config, 0)\n",
    "longLayer = ContextBERTLayer1(model1.config, layer_id=0)\n",
    "\n",
    "longPooler = ContextBERTPooler1(model1.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695cda6f",
   "metadata": {},
   "source": [
    "## Initialize Input Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0f147c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 290.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_id shape:torch.Size([3, 2048])\tinput_mask shape:torch.Size([3, 2048])\n",
      "segment_id shape:torch.Size([3, 2048])\tlabel_id shape:torch.Size([3])\n",
      "seq_len shape:torch.Size([3, 1])\tcontext_id shape:torch.Size([3, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare data variables for each module\n",
    "train_features = convert_examples_to_features(train_examples, label_list, 2048, tokenizer, 1, False, 'persent')\n",
    "\n",
    "input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "seq_len = torch.tensor([[f.seq_len] for f in train_features], dtype=torch.long)\n",
    "context_ids = torch.tensor([f.context_ids for f in train_features], dtype=torch.long)\n",
    "\n",
    "global_attention_mask = torch.zeros_like(input_ids)\n",
    "global_attention_mask[:, 0] = 1\n",
    "token_type_ids = torch.zeros_like(input_ids)\n",
    "print(f'input_id shape:{input_ids.shape}\\tinput_mask shape:{input_mask.shape}\\nsegment_id shape:{segment_ids.shape}\\tlabel_id shape:{label_ids.shape}\\nseq_len shape:{seq_len.shape}\\tcontext_id shape:{context_ids.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "593cae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_id shape:torch.Size([3, 2048])\tattention_mask shape:torch.Size([3, 2048])\n",
      "context_id shape:torch.Size([3, 1])\n",
      "extended_attention_mask shape:  torch.Size([3, 2048])\n"
     ]
    }
   ],
   "source": [
    "# Merge local attention mask and global attention mask\n",
    "attention_mask = longModel._merge_to_attention_mask(input_mask, global_attention_mask)\n",
    "\n",
    "# Pad input variables based on window size\n",
    "padding_len, input_ids, attention_mask, token_type_ids, position_ids = longModel._pad_to_window_size(\n",
    "    input_ids, attention_mask, token_type_ids, None, model1.config.pad_token_id)\n",
    "print(f'input_id shape:{input_ids.shape}\\tattention_mask shape:{attention_mask.shape}\\ncontext_id shape:{context_ids.shape}')\n",
    "\n",
    "# Minus 10000 for masking effect\n",
    "extended_attention_mask = get_extended_attention_mask(attention_mask, input_ids.size(), device)[:, 0, 0, :]\n",
    "print('extended_attention_mask shape: ', extended_attention_mask.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334d597",
   "metadata": {},
   "source": [
    "# Testing Embedding Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5d9e77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_output shape:torch.Size([3, 2048, 768])\n",
      "context_embedding_output shape: torch.Size([3, 2048, 768])\n"
     ]
    }
   ],
   "source": [
    "embedding_output = longEmbedding(input_ids, token_type_ids)\n",
    "print(f'embedding_output shape:{embedding_output.shape}')\n",
    "\n",
    "context_embedded = nn.Embedding(2375, model1.config.hidden_size)(context_ids).squeeze(dim=1)\n",
    "context_embedding_output = torch.stack(2048*[context_embedded], dim=1)\n",
    "print(f'context_embedding_output shape: {context_embedding_output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ac091",
   "metadata": {},
   "source": [
    "# Testing SelfAttention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "670641b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_output shape:  torch.Size([3, 2048, 768])\n"
     ]
    }
   ],
   "source": [
    "# Find global indices\n",
    "is_index_masked = extended_attention_mask < 0\n",
    "is_index_global_attn = extended_attention_mask > 0\n",
    "is_global_attn = is_index_global_attn.flatten().any().item()\n",
    "\n",
    "deep_context_hidden = torch.cat([context_embedding_output, embedding_output], dim=-1)\n",
    "deep_context_hidden = longEncoder.context_layer[0](deep_context_hidden)\n",
    "deep_context_hidden += context_embedding_output\n",
    "\n",
    "attn_output, new_attn_probs = longSelfAttn(embedding_output, extended_attention_mask, device, None,\n",
    "                     is_index_masked, is_index_global_attn, is_global_attn, deep_context_hidden)\n",
    "print('attention_output shape: ', attn_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc89ad",
   "metadata": {},
   "source": [
    "# Testing SelfAttentionOutput Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf5dc551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_output shape (after dense, norm, dropout):  torch.Size([3, 2048, 768])\n"
     ]
    }
   ],
   "source": [
    "attention_output = longSelfOut(attn_output, embedding_output)\n",
    "print('attention_output shape (after dense, norm, dropout): ', attention_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630f06c",
   "metadata": {},
   "source": [
    "# Testing Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "784b433f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_output shape (for Attention Module):  torch.Size([3, 2048, 768])\n"
     ]
    }
   ],
   "source": [
    "attention_output1, attention_probs = longAttention(embedding_output, extended_attention_mask, device, None,\n",
    "                     is_index_masked, is_index_global_attn, is_global_attn, deep_context_hidden)\n",
    "print('attention_output shape (for Attention Module): ', attention_output1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab971aa5",
   "metadata": {},
   "source": [
    "# Testing Layer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "31b1526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_output shape (after feed-forward, dense, norm, dropout):  torch.Size([3, 2048, 768])\n"
     ]
    }
   ],
   "source": [
    "layer_output, _, _, _ = longLayer(embedding_output, extended_attention_mask, device, None,\n",
    "                     is_index_masked, is_index_global_attn, is_global_attn, deep_context_hidden)\n",
    "print('layer_output shape (after feed-forward, dense, norm, dropout): ', layer_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052bf3bd",
   "metadata": {},
   "source": [
    "# Testing Encoder Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97befa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output shape (from Encoder Module):  torch.Size([3, 2048, 768])\n"
     ]
    }
   ],
   "source": [
    "all_encoder_layers, all_new_attention_probs, _, _ = longEncoder(embedding_output, extended_attention_mask, device,\n",
    "                                                               deep_context_hidden, None, padding_len)\n",
    "sequence_output = all_encoder_layers[-1]\n",
    "print('Final output shape (from Encoder Module): ', sequence_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608201c7",
   "metadata": {},
   "source": [
    "# Testing Pooler Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed150ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooled_output shape:  torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "pooled_output = longPooler(sequence_output, attention_mask)\n",
    "print('pooled_output shape: ', pooled_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5129ff5",
   "metadata": {},
   "source": [
    "# Testing Model Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9fcdb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooled_output shape (from Model Module):  torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "pooled_output1, _, _, _, _ = longModel(input_ids, token_type_ids, attention_mask, device, context_ids, \n",
    "                        global_attention_mask=global_attention_mask,\n",
    "                        head_mask=None,\n",
    "                        position_ids=None,)\n",
    "print('pooled_output shape (from Model Module): ', pooled_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45580c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
